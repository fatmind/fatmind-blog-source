title: 服务模型IO处理演进
date: 2014-07-14 08:34:28
tags:
---

**一、IO处理演进**

*早在计算机自身io控制，也经历 ‘程序io -> 中断io -> DMA’ 过程，目的为 ‘减弱io操作对cpu影响，保证将资源充分用在逻辑处理上，提升计算能力’。细节参考：[io控制方式](http://oa.gdut.edu.cn/os/multimedia/oscai/chapter5/pages/ch52.htm)*

站在应用程序角度，也是同样道理。下面来梳理下web请求的演进过程：

1. 单进程
不管多少请求，后端只有一个进程在串行处理。当并行请求量增大后，则完全无法满足。

2. 多进程
多进程能初步解决并行请求量大的问题，但随着请求进一步增大，内存很快被耗尽。
进程资源占用，参见：[pcb](http://oa.gdut.edu.cn/os/multimedia/oscai/chapter2/pages/ch22.htm)

3. 多线程
	- 线程相对进程的开销要小很多，且用线程池方式可进一步降低创建和销毁的代价。但每个线程都拥有独立的堆栈，仍需要占用一定的内存空间。
	- cpu在任意时刻只能做一件事情，线程之间通过切分时间片方式保证均匀使用cpu，当切换线程时也需切换其上下文，当线程量过多时，其代价就很明显。
	- 基于上面2点，在大并发量时，多线程还是无法满足。
	- 更多参考：[c10k](http://www.kegel.com/c10k.html)

4. 再改进
	- 先抛开‘异步、事件驱动等’这些概念。想想之所以有多进程/线程，本质是为解决‘IO阻塞’导致处理能力下降，希望充分利用CPU处理能力，但又面临资源的限制和切换的代价。
	- 有非阻塞IO吗？有（操作系统支持，语言层面如JavaNIO支持非阻塞）。可如何判断‘IO是否完成’？立即返回的并不是业务层期望的数据，而仅仅是当前的调用状态。你有思路吗？
	- 假设上一问题已解决，则单线程是更合适的选择，不仅能避免避免内存开销和上下文切换的代价，同时多线程编程中的死锁、状态同步也让人头疼。此时其上限取决于CPU计算能力，伸缩性更好。但也随即面临 ‘健壮性、多核利用’的问题，你有思路吗？
	**推荐：有哥们实现了一个比nginx速度更快的HTTP服务器**（想想业务代码咋写？）
http://www.cnblogs.com/clowwindy/archive/2011/09/23/a_http_server_faster_than_nginx.html

**二、细说：非阻塞IO与事件驱动** 

先说下事件驱动这个概念。来源于用户界面类程序，如点击按钮。在程序设计上，先注册事件，背后有一个事件循环，不断检查是否有事件要处理，若有则分发给对应注册的回调函数。
参见wiki解释http://zh.wikipedia.org/wiki/%E4%BA%8B%E4%BB%B6%E9%A9%85%E5%8B%95%E7%A8%8B%E5%BC%8F%E8%

扩展下，一次IO请求也可以看作事件。无需阻塞占用资源，当完成后回调处理。其前提也是‘非阻塞IO’。
可如何判断非阻塞IO是否完成？其作用等同“事件驱动的事件循环”。下面就一起看看轮询技术的演进：

1.read
while(true){read}，最原始、性能最低，cpu一直耗费在等待上。

2.select
对read改进，通过对文件描述符的事件状态来进行判断。
有一个较弱的限制，它采用1024长度的数组来存储状态，所以它最多可以同时检查1024个文件描述符。
推荐阅读：[select实现](http://blog.chinaunix.net/uid-20643761-id-1594860.html)，核心步骤：
- 循环遍历它所监测的fd_set内的所有文件描述符对应的驱动程序的poll函数
- 驱动程序提供的poll函数首先会将调用select的用户进程插入到该设备驱动对应资源的等待队列(如读/写等待队列)，然后返回一个bitmask告诉select当前资源哪些可用
- 当select遍历完fd_set内的所有设备文件，发现没有文件描述符可操作时(即retval=0),则调用schedule_timeout(_timeout)进入睡眠状态
- 在timeout时间内，只要任意个设备变为可操作，都会立即唤醒该进程（当设备驱动发现自身资源变为可读写并且有进程睡眠在该资源的等待队列上时，就会唤醒这个资源等待队列上的进程），从而继续执行遍历

3.poll
采用链表方式避免数组长度的限制，其它无变化

4.epoll
当描述符较多时，每次遍历的性能还是十分低下。
提供三个函数：epoll_create,epoll_ctl和epoll_wait，epoll_create是创建一个epoll句柄；epoll_ctl是注册要监听的事件类型；epoll_wait则是等待事件的产生。
优化点：
- 当调用epoll_wait时，判断【就绪链表】中有没有就绪的fd，若没有，则把current进程加入设备的等待队列中，并注册回调函数
- 在一个while(1)循环中判断就绪队列是否为空，结合schedule_timeout实现睡一会，判断一会的效果
- 如果current进程在睡眠中，设备就绪，会调用回调函数。在回调函数中，会把就绪的fd放入就绪链表，并唤醒等待队列中的current进程。继续执行就绪链表的遍历
- 以及mmap加速内核与用户态数据传递，详情参见这篇文章http://www.cnblogs.com/apprentice89/p/3234677.html

**三、再理想一点**

*注：此部分主要参考<深入浅出nodejs-第三章>*

轮询满足了非阻塞IO获取完整数据的需求（循环事件），但在应用程序角度，等待期间，CPU要么在轮询，要么在休眠等待时间发生。
再理想一点：应用程序发起非阻塞调用，无需轮询，可以直接处理下一个任务，只需要IO在完成后通过回调函数将数据传递给应用程序，从上一次代码位置继续执行。

1. 骨感的现实
在linux下幸运的存在这种方式，但存在缺陷（仅支持内核0_direct方式读取，无法利用系统缓存）
模拟：让部分线程‘非阻塞IO+轮询’来完成数据获取，让另一个线程进行计算处理，通过线程间的通信将IO得到的数据进行传输，实现异步IO。如：libeio，http://codingcat.net/blog/2012/11/01/libeio-source-analytics/

2. 想想业务代码。一次业务，涉及与外部系统多次交互，异常处理、上下文等，怎么处理？以及需要权衡代码的可理解性？
为什么nginx可以走通？在处理逻辑的抽象上有啥差异？

3. 单线程/进程，面临：多核利用、健壮性问题，如何解决？

*注：今天先到这，写不动了。后续这部分会结合nodejs/nginx+lua，再进一步讨论。谢谢你的阅读。*

---

**三、资料**
1.ngnix开发入门到精通
http://tengine.taobao.org/book/index.html
2.实现了一个比nginx速度更快的HTTP服务器
http://www.cnblogs.com/clowwindy/archive/2011/09/23/a_http_server_faster_than_nginx.html
3.libeio
http://codingcat.net/blog/2012/11/01/libeio-source-analytics/



